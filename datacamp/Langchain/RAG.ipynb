{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG Retrieval Augmented Generation\n",
    "Use embeddings to retrieve relevant information to integrate into the prompt\n",
    "\n",
    "Document Loader -----> Splitting -----> Storage + Retrieval\n",
    "\n",
    "### LangChain document loaders\n",
    "Classes designed to load and configure documents for system integration\n",
    "Document loaders for common file types: `.pdf`, `.csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### PDF doucument Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Abstract \n",
      " \n",
      "This comprehensive experiment investigates the principles and practical applications of error \n",
      "detection and correction in digital communication systems. Utilizing a suite of specialized \n",
      "equipment including the DCS297A Data Source, DCS297H Data Receiver, DCS297K Audio \n",
      "Module, and associated components, we conducted an in-depth examination of two key \n",
      "techniques: simple parity checking for error detection in seven-bit data words, and an advanced \n",
      "error correction code employing four data bits and four check bits. \n",
      " \n",
      "The study was designed to achieve two primary objectives: first, to demonstrate the capabilities \n",
      "and limitations of simple parity checking in detecting errors within transmitted data words, and \n",
      "second, to showcase the enhanced functionality of error correction codes in both locating and \n",
      "rectifying errors in digital communications. \n",
      " \n",
      "Our findings conclusively demonstrated that while simple parity checking is capable of detecting \n",
      "the presence of errors, it falls short in pinpointing their exact location within the data word. This \n",
      "limitation significantly constrains its practical utility in scenarios requiring high data integrity. In \n",
      "contrast, the implemented error correction code exhibited superior performance, successfully \n",
      "correcting single-bit errors and reliably detecting the occurrence of double-bit errors in \n",
      "transmitted data. \n",
      " \n",
      "These results underscore the critical importance of implementing robust error detection and \n",
      "correction mechanisms in digital communication systems. The ability to not only identify but \n",
      "also correct errors in transmitted data is paramount in ensuring the reliability and integrity of \n",
      "information in an increasingly digital world. This experiment provides valuable insights into the \n",
      "relative strengths and weaknesses of different error handling techniques, offering guidance for \n",
      "their application in real-world communication systems where data accuracy is crucial.' metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2024-08-22T20:39:25+00:00', 'author': 'Jayson Nick', 'moddate': '2024-08-22T20:39:25+00:00', 'source': '/Users/mac/Desktop/5.1/Datacom/LAB-REPORT.pdf', 'total_pages': 15, 'page': 1, 'page_label': '2'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"/Users/mac/Desktop/5.1/Datacom/LAB-REPORT.pdf\")\n",
    "\n",
    "data = loader.load()\n",
    "print(data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "\n",
    "loader = CSVLoader(\"/Users/mac/Desktop/5.1/Datacom/LAB-REPORT.csv\")\n",
    "data = loader.load()\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='This is a legacy site. Please use the latest v0.2 and v0.3 API references instead.\n",
      "\n",
      "langchain_community.document_loaders.pdf.PyPDFLoader\n",
      "\n",
      "PyPDFLoader\n",
      "\n",
      "PyPDFLoader.__init__()\n",
      "\n",
      "PyPDFLoader.alazy_load()\n",
      "\n",
      "PyPDFLoader.aload()\n",
      "\n",
      "PyPDFLoader.lazy_load()\n",
      "\n",
      "PyPDFLoader.load()\n",
      "\n",
      "PyPDFLoader.load_and_split()\n",
      "\n",
      "langchain_community.document_loaders.pdf.PyPDFLoaderÂ¶\n",
      "\n",
      "Examples using PyPDFLoaderÂ¶\n",
      "\n",
      "Apache Cassandra\n",
      "\n",
      "Astra DB\n",
      "\n",
      "Document Comparison\n",
      "\n",
      "Google Cloud Storage File\n",
      "\n",
      "Google Vertex AI Vector Search\n",
      "\n",
      "How to load PDFs\n",
      "\n",
      "KDB.AI\n",
      "\n",
      "Merge Documents Loader\n",
      "\n",
      "MongoDB Atlas\n",
      "\n",
      "Monetize your audience: Fund an OSS project or website with EthicalAds, a privacy-first ad network\n",
      "\n",
      "Ads by EthicalAds\n",
      "\n",
      "Â© 2023, LangChain, Inc. . Last updated on Dec 09, 2024.' metadata={'source': '/Users/mac/Downloads/langchain_community.document_loaders.pdf.PyPDFLoader â€” ðŸ¦œðŸ”— LangChain 0.2.17.html'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import UnstructuredHTMLLoader\n",
    "\n",
    "loader = UnstructuredHTMLLoader('/Users/mac/Downloads/langchain_community.document_loaders.pdf.PyPDFLoader â€” ðŸ¦œðŸ”— LangChain 0.2.17.html')\n",
    "data = loader.load()\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 53, which is longer than the specified 24\n",
      "Created a chunk of size 54, which is longer than the specified 24\n",
      "Created a chunk of size 32, which is longer than the specified 24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['One machine can do the work of fifty ordinary humans', 'No machine can do the work of one extraordinary human', 'It is a quote by Elbert Hubbard']\n",
      "[52, 53, 31]\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "\n",
    "quote = '''\n",
    "One machine can do the work of fifty ordinary humans.\\nNo machine can do the work of one extraordinary human. It is a quote by Elbert Hubbard.\n",
    "'''\n",
    "len(quote)\n",
    "chunk_size = 24\n",
    "chunk_overlap = 3\n",
    "\n",
    "ct_splitter = CharacterTextSplitter(\n",
    "    separator='.',\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap,\n",
    ")\n",
    "\n",
    "docs = ct_splitter.split_text(quote)\n",
    "\n",
    "print(docs)\n",
    "print([len(doc) for doc in docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['One machine can do the', 'work of fifty ordinary', 'humans.', 'No machine can do the', 'work of one', 'extraordinary human. It', 'It is a quote by Elbert', 'Hubbard.']\n"
     ]
    }
   ],
   "source": [
    "#  RecursiveCharacterTextSplitter\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "rc_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap,\n",
    ")\n",
    "docs = rc_splitter.split_text(quote)\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='This is a legacy site. Please use the latest v0.2 and v0.3 API references instead.\n",
      "\n",
      "langchain_community.document_loaders.pdf.PyPDFLoader\n",
      "\n",
      "PyPDFLoader\n",
      "\n",
      "PyPDFLoader.__init__()\n",
      "\n",
      "PyPDFLoader.alazy_load()\n",
      "\n",
      "PyPDFLoader.aload()\n",
      "\n",
      "PyPDFLoader.lazy_load()\n",
      "\n",
      "PyPDFLoader.load()\n",
      "\n",
      "PyPDFLoader.load_and_split()\n",
      "\n",
      "langchain_community.document_loaders.pdf.PyPDFLoaderÂ¶\n",
      "\n",
      "Examples using PyPDFLoaderÂ¶\n",
      "\n",
      "Apache Cassandra\n",
      "\n",
      "Astra DB\n",
      "\n",
      "Document Comparison\n",
      "\n",
      "Google Cloud Storage File\n",
      "\n",
      "Google Vertex AI Vector Search\n",
      "\n",
      "How to load PDFs\n",
      "\n",
      "KDB.AI\n",
      "\n",
      "Merge Documents Loader\n",
      "\n",
      "MongoDB Atlas\n",
      "\n",
      "Monetize your audience: Fund an OSS project or website with EthicalAds, a privacy-first ad network\n",
      "\n",
      "Ads by EthicalAds\n",
      "\n",
      "Â© 2023, LangChain, Inc. . Last updated on Dec 09, 2024.' metadata={'source': '/Users/mac/Downloads/langchain_community.document_loaders.pdf.PyPDFLoader â€” ðŸ¦œðŸ”— LangChain 0.2.17.html'}\n",
      "page_content='This is a legacy site.' metadata={'source': '/Users/mac/Downloads/langchain_community.document_loaders.pdf.PyPDFLoader â€” ðŸ¦œðŸ”— LangChain 0.2.17.html'}\n",
      "page_content='Please use the latest' metadata={'source': '/Users/mac/Downloads/langchain_community.document_loaders.pdf.PyPDFLoader â€” ðŸ¦œðŸ”— LangChain 0.2.17.html'}\n"
     ]
    }
   ],
   "source": [
    "# Splitting html\n",
    "from langchain_community.document_loaders import UnstructuredHTMLLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "loader = UnstructuredHTMLLoader('/Users/mac/Downloads/langchain_community.document_loaders.pdf.PyPDFLoader â€” ðŸ¦œðŸ”— LangChain 0.2.17.html')\n",
    "\n",
    "\n",
    "data = loader.load()\n",
    "\n",
    "print(data[0])\n",
    "\n",
    "rc_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap,\n",
    ")\n",
    "docs = rc_splitter.split_documents(data)\n",
    "print(docs[0])\n",
    "print(docs[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RAG Storage and Retrieval using Vector Databases (ChromaDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "\n",
    "message = '''\n",
    "Review and fix the following TechStack marketing copy with the following guidelines in consideration:\n",
    "\n",
    "Guidelines:\n",
    "{guidelines}\n",
    "\n",
    "Copy:\n",
    "{copy}\n",
    "\n",
    "Fixed Copy:\n",
    "'''\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages([('human', message)])\n",
    "\n",
    "\n",
    "embedding_function = OpenAIEmbeddings(model=\"text-embedding-ada-002\", api_key=api_key)\n",
    "\n",
    "vectorstore = Chroma.from_documents(\n",
    "    docs,\n",
    "    embedding=embedding_function,\n",
    "    persist_directory=\"/Users/mac/Desktop/Projects/ml-practice/datacamp/ChromaDB\",\n",
    ")\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 2}, search_type=\"similarity\")\n",
    "\n",
    "\n",
    "rag_chain = ({\n",
    "    'guidelines': retriever,\n",
    "    'copy': RunnablePassthrough(),\n",
    "} | prompt_template | llm )\n",
    "\n",
    "docs  = rag_chain.invoke('Some text to be fixed')\n",
    "print(docs[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
